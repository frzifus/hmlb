---
kind: Deployment
apiVersion: apps/v1
metadata:
  name: llamastack
  namespace: llm
spec:
  selector:
    matchLabels:
      app: llamastack
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 1
    type: RollingUpdate
  template:
    metadata:
      annotations:
        instrumentation.opentelemetry.io/inject-python: "true"
      labels:
        app: llamastack
    spec:
      volumes:
        - name: run-config-volume
          configMap:
            name: run-config
            defaultMode: 420
        - name: cache
          emptyDir: {}
        - name: pythain
          emptyDir: {}
      containers:
        - resources: {}
          terminationMessagePath: /dev/termination-log
          name: llamastack
          env:
            - name: VLLM_MAX_TOKENS
              #value: '32768'
              value: '64000'
            - name: VLLM_URL
              value: 'http://llama-cpp:8080/v1'
            - name: INFERENCE_MODEL
              value: '/root/.cache/llama.cpp/ggml-org_gemma-3-12b-it-qat-GGUF_gemma-3-12b-it-qat-Q4_0.gguf'
            - name: TAVILY_SEARCH_API_KEY
              valueFrom:
                secretKeyRef:
                  name: tavily-search-api-secret
                  key: TAVILY_SEARCH_API_KEY
            # - name: MILVUS_DB_PATH
            #   value: milvus.db
            # # NOTE: trace endpoint is
            - name: CUSTOM_OTEL_TRACE_ENDPOINT
              value: 'http://backend-collector.observability.svc.cluster.local:4318/v1/traces'
            - name: TELEMETRY_SINKS
              value: 'otel_trace'
          ports:
            - containerPort: 8321
              protocol: TCP
          volumeMounts:
            - name: pythain
              mountPath: /pythainlp-data
            - name: run-config-volume
              mountPath: /app-config
            # - name: llama-persist
            #   mountPath: /.llama
            - name: cache
              mountPath: /.cache
          terminationMessagePolicy: File
          image: 'llamastack/distribution-remote-vllm:0.2.12'
          args:
            - '--config'
            - /app-config/config.yaml
      securityContext: {}
